Focus:
    1. goal-base agent
    2. Atomic Rep: states consider as whole, no internal structure
    3. Uninformed vs Informed


Arad to Burcharest
    RouteFinding Problem
    Given:
        observable env: know about it s current state
        discrete env: given state finite actions
        know env: which states are reached by each action
        deterministic: each action has one outcome

Define problem
    1. Init state
        In(Arad)
    2. Possible Actions
        Actions (state s) : Actions ( In(Arad) ) { Go (Sibu), Go (Timisoara), Go (Zerind) }
    3. Transition model
        Result ( In(Arad), Go(Zerind) ) = In(Zerind)
    //These 3 above forms a state space of the problem
    4. Goal test
        Set { In(Bucharest) }
    5. Path cost function

Searching for Solutions:
    search tree, satate = node
    expanding current state and generate new set of state
    frontier = open list
    explored set = close list

Measuring performance
    Completeness: Guaranteed to find solution
    Optimality: find optimal solution
    Time complexity: how long
    Space: How much memory

    Graph: Branching Factor (max successors) and depth (shallowest node)

UnInformed Search:
    Doesnt know which non-goal state is more promising

    BFS:
        _ optimal if same path cost
        _ O(b^d) time and space
    DFS:
        _ not optimal (afraid infinite state space)
        _ Tree Search (not avoid redundant path) is incomplete
        _ require only O(bm) storage (m = max depth)

Informed Search
        _ f(n) evaluation function: cost estimate
        _ h(n) heuristic function: estimate cost of cheapest path to goal from n

   Greedy best-first search
        _ expand node closest to goal f(n) = h(n)
        _ not optimal and incomplete